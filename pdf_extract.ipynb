{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "%cd /home/kai/muku_esg/ESG-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = x.replace('\\n', '')\n",
    "    x = re.sub(r'[!\\\"#$%&\\'()*\\+,-.\\/:;<=>?@\\[\\\\\\]^_`{|}~]', '', x)\n",
    "    x = x.replace('\\t', ' ')\n",
    "    if len(x.split()) < 5:\n",
    "        return None\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascii(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]', '', text)\n",
    "    text = re.sub(r'[\\x0C]', r\"\\n\\n\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './taiwan_pdf/2_tsmc_1_210.pdf'\n",
    "# text = extract_text(file_name, page_numbers=[i for i in range(15)])\n",
    "text = extract_text(file_name, page_numbers=[11])\n",
    "text = ascii(text)\n",
    "text = text.strip('\\\"')\n",
    "paragraph = re.split(r'\\n\\s*\\n', text)\n",
    "paragraph = map(preprocess, paragraph)\n",
    "paragraph = [x for x in paragraph if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(paragraph))\n",
    "for i in range(len(paragraph)):\n",
    "    print(paragraph[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = ['To fulfill our commitment to our Diversity and Inclusion Statement', ', the Company treats its workforce as the most important asset and is \\\n",
    "committed to empowering more than 60,000 employees globally to unleash their full potential in the right roles',\n",
    "'In supporting employees to balance family life and career development, TSMC offers a welfare system that is better than legal \\\n",
    "requirements and has established four preschool for fabs in Taiwan',\n",
    "'Weather is the state of the atmosphere, describing for example the degree to which it is hot or cold, wet or dry, calm or stormy, clear or cloudy.',\n",
    "'On Earth, most weather phenomena occur in the lowest layer of the planets atmosphere, the troposphere, just below the stratosphere',\n",
    "'Weather refers to day-to-day temperature, precipitation, and other atmospheric conditions, whereas climate is the term for the averaging of atmospheric conditions over longer periods of time.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "while ind < len(paragraph) - 1:\n",
    "    # if len(paragraph[ind].split()) + len(paragraph[ind+1].split()) >= 500:\n",
    "    #     ind += 1\n",
    "    prompt = paragraph[ind]\n",
    "    next_sentence = paragraph[ind+1]\n",
    "    print('prompt', prompt)\n",
    "    print('next_sentence', next_sentence)\n",
    "    encoding = tokenizer(prompt, next_sentence, truncation=True, return_tensors=\"pt\")\n",
    "    outputs = model(**encoding, labels=torch.LongTensor([1]))\n",
    "    logits = outputs.logits\n",
    "    print(logits)\n",
    "    if logits[0, 0] > logits[0, 1]:  # next sentence was random\n",
    "        paragraph[ind:ind+2] = [' '.join(paragraph[ind:ind+2])]\n",
    "    else:\n",
    "        ind += 1\n",
    "    if len(paragraph[ind].split()) >= 500:\n",
    "        ind += 1\n",
    "print(len(paragraph))\n",
    "print(paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esgbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07ab08fa76665a89038b50b331dd9223d4e470d2d4facccdbf60961d882d1011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
